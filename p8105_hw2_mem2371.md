Homework 2
================
Megan Marziali

This document contains a solution to homework 2 for p8105.

``` r
library(tidyverse)
library(readxl)
```

# Problem 1

## Read and clean Mr. Trash Wheel

The following code imports the Mr. Trash Wheel data and cleans the data.

``` r
trash_wheel = 
  read_xlsx("./problem_1/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
            sheet = "Mr. Trash Wheel",
            range = "A2:N408",
            na = "") %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(sports_balls_int = 
           (round(sports_balls) %>% 
           as.integer()))
```

## Read and clean precipitation data

The code below reads in and cleans precipitation data.

``` r
precip_2017 = 
  readxl::read_excel("./problem_1/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
                     sheet = "2017 Precipitation",
                     range = "A2:B14"
                     ) %>% 
  janitor::clean_names() %>% 
  mutate(year = "2017") %>% 
  drop_na(month) %>% 
  relocate(year)

precip_2018 = 
  readxl::read_excel("./problem_1/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
                     sheet = "2018 Precipitation",
                     range = "A2:B14"
                     ) %>% 
  janitor::clean_names() %>% 
  mutate(year = "2018") %>% 
  drop_na(month) %>% 
  relocate(year)
```

Joining data and converting month to a character variable.

``` r
month_df = 
  tibble(
    month = 1:12,
    month_name = month.name)

precip_df = 
   bind_rows(precip_2018, precip_2017)

left_join(precip_df, month_df, by = "month")
```

This dataset contains information from the Mr. Trash Wheel trash
collector in Balitmore, Maryland. As trash enters the inner harbour, the
trash wheel collects that trash and stores it in a dumpster. The dataset
contains information on year, month and trash collected, including some
specific types of trash. There are a total of 344 observations in our
final dataset. Additional information is included on precipitation data.

Within the precipitation dataset, there are 12 observations from 2017
and 12 from 2018. The total amount of precipitation in 2017 amounted to
32.93 inches, and 70.33 inches in 2018. The mean and median for
precipitation in 2017 was 2.74 (SD: 2.22) and 2.14 (IQR: 2.82),
respectively; with 2018, the mean precipitation was 5.86 (SD: 3.13) and
median precipitation was 2.14 (IQR: 2.82).

# Problem 2

## Reading in transit data

The following code chunk reads in the NYC transit subway data and cleans
it up.

``` r
transit_df = 
  read_csv("./problem_2/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
           na = "") %>% 
  janitor::clean_names() %>% 
  select(-division,
         -exit_only,
         -staffing,
         -staff_hours,
         -ada_notes,
         -free_crossover,
         -north_south_street,
         -east_west_street,
         -corner,
         -entrance_latitude,
         -entrance_longitude,
         -station_location,
         -entrance_location) %>% 
  mutate(entry = (recode(entry, YES = "TRUE",
                                NO = "FALSE"))) %>% 
  mutate(route8 = as.character(route8),
         route9 = as.character(route9),
         route10 = as.character(route10),
         route11 = as.character(route11))
```

The NYC transit subway dataset contains information regarding lines,
station names and locations (specifically, latitude and longitude),
routes, entry, entrance types, vending and ADA compliance. To clean the
dataset, I have dropped unnecessary variables, cleaned the column names,
cleaned variable types to be consistent, and recoded the entry variable
to logical vector. I have also indicated that blank cells in the excel
sheet correspond to missing values. This dataset has 1868 rows and 19
columns. The dataset is not tidy, because the route names should be
transformed to rows in lieu of columns.

## Questions about the transit data

#### Distinct stations

The following code chunk is to create a data frame with distinct
stations defined both by name and line.

``` r
transit_distinct = 
  transit_df %>% 
  distinct(line, station_name, .keep_all = TRUE) 
```

There are 465 distinct stations included in this dataset.

#### ADA compliance

There are 84 of the distinct stations that are ADA compliant. Of the
total stations (not the distinct stations), there are 468 stations that
are ADA compliant.

#### Entry without vending

The following code chunk restricts to only stations without vending.

``` r
transit_no_vend = 
  filter(transit_df, vending == "NO")
```

There are 69 stations without vending that allow entry of the 183 total
stations without vending. So, 38% of the stations without vending allow
entry.

## Reformatting the transit data

The code chunk below is built to reformat the data to be distinct route
names and route numbers.

``` r
transit_df_long = 
  pivot_longer(
    transit_df,
    route1:route11,
    names_to = "route_name",
    values_to = "route_num"
  ) %>% 
  drop_na(route_num)

transit_a = 
  transit_df_long %>% 
  distinct(line, station_name, .keep_all = TRUE) %>% 
  filter(route_num == "A")
```

There are 60 stations that serve the A train. There are 17 stations that
are ADA compliant that serve the A train.

# Problem 3

## Reading in the FiveThirtyEight data

The following code reads in and cleans the pols-month data.

``` r
pols_month = 
  read_csv("./problem_3/fivethirtyeight_datasets/pols-month.csv") %>% 
  separate(
    mon,
    sep = "-",
    into = c("year", "month", "day")) %>% 
  mutate(year = as.integer(year),
         month = as.integer(month),
         president = 
           ifelse(prez_dem == 1, 
                  {president = "dem"}, 
                  {president = "gop"}))

pols_cleaned = 
  left_join(pols_month, month_df, by = "month") %>% 
  select(-prez_gop, 
         -prez_dem, 
         -day)
```

This code chunk reads in and cleans the snp dataset.

``` r
snp_df = 
  read_csv("./problem_3/fivethirtyeight_datasets/snp.csv") %>% 
  separate(
    date,
    sep = "/",
    into = c("month", "day", "year")) %>% 
  mutate(year = as.integer(year),
         month = as.integer(month),
         day = as.integer(day)) %>% 
  relocate(year, month)

snp_month = 
  left_join(snp_df, month_df, by = "month") 
```

This code chunk reads in and cleans the unemployment dataset.

``` r
unemployment_df = 
  read_csv("./problem_3/fivethirtyeight_datasets/unemployment.csv") %>% 
  pivot_longer(
    Jan:Dec,
    names_to = "month_name",
    values_to = "unemployment") %>% 
  mutate(
    month = match(month_name, month.abb),
    year = as.integer(Year)) %>% 
  select(-Year) %>% 
  relocate(year, month)
```

## Merging datasets

The following code merges snp into pols, and merging the result with
unemployment.

``` r
pols_snp_merge = 
  left_join(pols_cleaned, snp_month, by = c("year", "month", "month_name"))

full_merge = 
  left_join(pols_snp_merge, unemployment_df, by = c("year", "month", "month_name"))
```

## Dataset descriptions

The snp dataset relates to Standard & Poor’s stock market index, and
includes year, month, date and the values of the S\&P stock market index
at close. There are 787 observations in the dataset, and 4 columns. The
yearly range from this dataset is from 1950 to 2015.

The pols dataset contains information on the number of national
politicians and their political affiliations. This dataset includes 10
columns: year, month, gov\_gop, sen\_gop, rep\_gop, gov\_dem, sen\_dem,
rep\_dem, president, month\_name. There are 822 observations in this
dataset. The yearly range from this dataset is from 1947 to 2015.

The unemployment dataset contains information regarding the percentage
of unemployment during a given period. This dataset contains year, month
and unemployment rate. There are 816 observations in this dataset and 4
columns. The yearly range from this dataset is from 1948 to 2015.

The merged dataset, which merged the snp, pol and unemployment datasets,
includes 822 observations and 13 columns. The year range from this
merged dataset is from 1947 to 2015.
